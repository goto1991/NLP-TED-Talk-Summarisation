{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Text Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "    \n",
    "raw_text = doc.xpath('//content/text()')\n",
    "raw_summary = doc.xpath('//head/description/text()')\n",
    "\n",
    "del doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "talk_sentences = []\n",
    "talknum = len(raw_text)\n",
    "\n",
    "for i in range(talknum):\n",
    "    temp = re.sub(r'\\([^)]*\\)', '', raw_text[i])\n",
    "    temp = re.sub(r'\\n', '', raw_text[i])\n",
    "    temp = temp.split('.')\n",
    "    talk_sentences.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_sentences = []\n",
    "talknum = len(raw_summary)\n",
    "\n",
    "for i in range(talknum):\n",
    "    temp = re.sub(r'\\([^)]*\\)', '', raw_summary[i])\n",
    "    temp = re.sub(r'\\n', '', raw_summary[i])\n",
    "    temp = temp.split('.')\n",
    "    summary_sentences.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation\n"
     ]
    }
   ],
   "source": [
    "print(talk_sentences[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " He shares insights on how to strike a balance between perfecting what we already know and exploring totally new ideas -- and lays out how to avoid two major strategy traps\n"
     ]
    }
   ],
   "source": [
    "print(summary_sentences[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "talk_sentence_word = []\n",
    "\n",
    "for talk in talk_sentences:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent.lower()).split()\n",
    "        temp.append(tokens)#\n",
    "    talk_sentence_word.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_sentence_word = []\n",
    "\n",
    "for talk in summary_sentences:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent.lower()).split()\n",
    "        temp.append(tokens)#\n",
    "    summary_sentence_word.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'me',\n",
       " 'the',\n",
       " 'real',\n",
       " 'real',\n",
       " 'solution',\n",
       " 'to',\n",
       " 'quality',\n",
       " 'growth',\n",
       " 'is',\n",
       " 'figuring',\n",
       " 'out',\n",
       " 'the',\n",
       " 'balance',\n",
       " 'between',\n",
       " 'two',\n",
       " 'activities',\n",
       " 'exploration',\n",
       " 'and',\n",
       " 'exploitation']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk_sentence_word[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he',\n",
       " 'shares',\n",
       " 'insights',\n",
       " 'on',\n",
       " 'how',\n",
       " 'to',\n",
       " 'strike',\n",
       " 'a',\n",
       " 'balance',\n",
       " 'between',\n",
       " 'perfecting',\n",
       " 'what',\n",
       " 'we',\n",
       " 'already',\n",
       " 'know',\n",
       " 'and',\n",
       " 'exploring',\n",
       " 'totally',\n",
       " 'new',\n",
       " 'ideas',\n",
       " 'and',\n",
       " 'lays',\n",
       " 'out',\n",
       " 'how',\n",
       " 'to',\n",
       " 'avoid',\n",
       " 'two',\n",
       " 'major',\n",
       " 'strategy',\n",
       " 'traps']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_sentence_word[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = list(zip(talk_sentence_word, summary_sentence_word))\n",
    "random.shuffle(temp)\n",
    "talk_sentence_word_shuffle, summary_sentence_word_shuffle = zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = talk_sentence_word_shuffle[:1835]\n",
    "test_data = talk_sentence_word_shuffle[1835:]\n",
    "\n",
    "train_summaries = summary_sentence_word_shuffle[:1835]\n",
    "test_summaries = summary_sentence_word_shuffle[1835:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085,)\n",
      "(2085,)\n",
      "(1835,)\n",
      "(250,)\n",
      "(1835,)\n",
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(talk_sentence_word_shuffle))\n",
    "print(np.shape(summary_sentence_word_shuffle))\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(train_summaries))\n",
    "print(np.shape(test_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_talk_lenghts = []\n",
    "\n",
    "for talk in train_data:\n",
    "    N = 0\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            N += 1\n",
    "    train_talk_lenghts.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_summary_lenghts = []\n",
    "\n",
    "for talk in train_summaries:\n",
    "    N = 0\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            N += 1\n",
    "    train_summary_lenghts.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3641, 3243, 3357, 431, 2388, 1235, 2749, 769, 1885, 1492]\n",
      "[36, 70, 57, 64, 73, 60, 47, 47, 66, 52]\n"
     ]
    }
   ],
   "source": [
    "print(train_talk_lenghts[:10])\n",
    "print(train_summary_lenghts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_talk_lenghts = []\n",
    "\n",
    "for talk in test_data:\n",
    "    N = 0\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            N += 1\n",
    "    test_talk_lenghts.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_summary_lenghts = []\n",
    "\n",
    "for talk in test_summaries:\n",
    "    N = 0\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            N += 1\n",
    "    test_summary_lenghts.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1585, 2804, 1848, 1157, 2808, 931, 2942, 1308, 801, 790]\n",
      "[29, 50, 116, 53, 43, 88, 39, 50, 52, 62]\n"
     ]
    }
   ],
   "source": [
    "print(test_talk_lenghts[:10])\n",
    "print(test_summary_lenghts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641\n"
     ]
    }
   ],
   "source": [
    "train_talk_word = []\n",
    "\n",
    "for talk in train_data:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            temp.append(word)\n",
    "    train_talk_word.append(temp)\n",
    "    \n",
    "print(len(train_talk_word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "train_summary_word = []\n",
    "\n",
    "for talk in train_summaries:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            temp.append(word)\n",
    "    train_summary_word.append(temp)\n",
    "    \n",
    "print(len(train_summary_word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585\n"
     ]
    }
   ],
   "source": [
    "test_talk_word = []\n",
    "\n",
    "for talk in test_data:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            temp.append(word)\n",
    "    test_talk_word.append(temp)\n",
    "    \n",
    "print(len(test_talk_word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "test_summary_word = []\n",
    "\n",
    "for talk in test_summaries:\n",
    "    temp = []\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            temp.append(word)\n",
    "    test_summary_word.append(temp)\n",
    "    \n",
    "print(len(test_summary_word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "N = 1\n",
    "\n",
    "for talk in train_data:\n",
    "    for sent in talk:\n",
    "        for word in sent:\n",
    "            if word in vocab:\n",
    "                N = N\n",
    "            else:\n",
    "                vocab[word] = N\n",
    "                N += 1\n",
    "                \n",
    "vocab[\"unknown_word\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52083\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_talk_word_index = []\n",
    "\n",
    "for talk in train_talk_word:\n",
    "    temp = []\n",
    "    for word in talk:\n",
    "        if word in vocab:\n",
    "            temp.append(vocab[word])\n",
    "        else:\n",
    "            temp.append(vocab[\"unknown_word\"])\n",
    "    train_talk_word_index.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_summary_word_index = []\n",
    "\n",
    "for talk in train_summary_word:\n",
    "    temp = []\n",
    "    for word in talk:\n",
    "        if word in vocab:\n",
    "            temp.append(vocab[word])\n",
    "        else:\n",
    "            temp.append(vocab[\"unknown_word\"])\n",
    "    train_summary_word_index.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_talk_word_index = []\n",
    "\n",
    "for talk in test_talk_word:\n",
    "    temp = []\n",
    "    for word in talk:\n",
    "        if word in vocab:\n",
    "            temp.append(vocab[word])\n",
    "        else:\n",
    "            temp.append(vocab[\"unknown_word\"])\n",
    "    test_talk_word_index.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_summary_word_index = []\n",
    "\n",
    "for talk in test_summary_word:\n",
    "    temp = []\n",
    "    for word in talk:\n",
    "        if word in vocab:\n",
    "            temp.append(vocab[word])\n",
    "        else:\n",
    "            temp.append(vocab[\"unknown_word\"])\n",
    "    test_summary_word_index.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_talk_word_index_exp = []\n",
    "\n",
    "for i in range(len(train_talk_word_index)):\n",
    "    temp = []\n",
    "    for j in range(max(train_talk_lenghts)):\n",
    "        if j <= (train_talk_lenghts[i]-1):\n",
    "            temp.append(train_talk_word_index[i][j])\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    train_talk_word_index_exp.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_summary_word_index_exp = []\n",
    "\n",
    "for i in range(len(train_summary_word_index)):\n",
    "    temp = []\n",
    "    for j in range(max(train_summary_lenghts)):\n",
    "        if j <= (train_summary_lenghts[i]-1):\n",
    "            temp.append(train_summary_word_index[i][j])\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    train_summary_word_index_exp.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_talk_word_index_exp = []\n",
    "\n",
    "for i in range(len(test_talk_word_index)):\n",
    "    temp = []\n",
    "    for j in range(max(test_talk_lenghts)):\n",
    "        if j <= (test_talk_lenghts[i]-1):\n",
    "            temp.append(test_talk_word_index[i][j])\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    test_talk_word_index_exp.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_summary_word_index_exp = []\n",
    "\n",
    "for i in range(len(test_summary_word_index)):\n",
    "    temp = []\n",
    "    for j in range(max(test_summary_lenghts)):\n",
    "        if j <= (test_summary_lenghts[i]-1):\n",
    "            temp.append(test_summary_word_index[i][j])\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    test_summary_word_index_exp.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    \n",
    "    pass\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_seq_length = 16\n",
    "output_seq_length = 15\n",
    "batch_size = 128\n",
    "\n",
    "input_vocab_size = 70\n",
    "output_vocab_size = 28\n",
    "embedding_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_input = [tf.placeholder(tf.int32, \n",
    "                                shape=(None,),\n",
    "                                name = \"ei_%i\" %i)\n",
    "                                for i in range(input_seq_length)]\n",
    "\n",
    "labels = [tf.placeholder(tf.int32,\n",
    "                                shape=(None,),\n",
    "                                name = \"l_%i\" %i)\n",
    "                                for i in range(output_seq_length)]\n",
    "\n",
    "decode_input = [tf.zeros_like(encode_input[0], dtype=np.int32, name=\"GO\")] + labels[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x7fd528b076d8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x7fd528b077f0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x7fd528b078d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "embedding_rnn_seq2seq() got an unexpected keyword argument 'reuse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1f9caff2bda0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decoders\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     decode_outputs, decode_state = tf.nn.seq2seq.embedding_rnn_seq2seq(\n\u001b[0;32m---> 11\u001b[0;31m         encode_input, decode_input, stacked_lstm, input_vocab_size, output_vocab_size, reuse=True)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding_rnn_seq2seq() got an unexpected keyword argument 'reuse'"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "cells = [tf.nn.rnn_cell.DropoutWrapper(\n",
    "        tf.nn.rnn_cell.BasicLSTMCell(embedding_dim), output_keep_prob=keep_prob\n",
    "    ) for i in range(3)]\n",
    "\n",
    "stacked_lstm = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "\n",
    "with tf.variable_scope(\"decoders\") as scope:\n",
    "    decode_outputs, decode_state = tf.nn.seq2seq.embedding_rnn_seq2seq(\n",
    "        encode_input, decode_input, stacked_lstm, input_vocab_size, output_vocab_size, reuse=True)\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    decode_outputs_test, decode_state_test = tf.nn.seq2seq.embedding_rnn_seq2seq(\n",
    "        encode_input, decode_input, stacked_lstm, input_vocab_size, output_vocab_size,\n",
    "    feed_previous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
